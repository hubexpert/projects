{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYy-2e-_oMBq",
    "outputId": "b1d872ea-b2dd-4e07-f00a-db70aea320fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe: 112120\n",
      "After removing missing images: 10000\n",
      "Classes: ['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Effusion'\n",
      " 'Emphysema' 'Fibrosis' 'Hernia' 'Infiltration' 'Mass' 'No Finding'\n",
      " 'Nodule' 'Pleural_Thickening' 'Pneumonia' 'Pneumothorax']\n",
      "Train samples: 8463\n",
      "Test samples: 1537\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 119MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.2165\n",
      "Epoch 2/5, Loss: 0.1549\n",
      "Epoch 3/5, Loss: 0.1385\n",
      "Epoch 4/5, Loss: 0.1162\n",
      "Epoch 5/5, Loss: 0.0897\n",
      "Mean ROC AUC: 0.6562795468381261\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1. Import Libraries\n",
    "# ============================\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# ============================\n",
    "# 2. Load Metadata\n",
    "# ============================\n",
    "df = pd.read_csv('/content/drive/MyDrive/Data_Entry_2017_v2020.csv')\n",
    "\n",
    "print(\"Original dataframe:\", len(df))\n",
    "\n",
    "# ============================\n",
    "# 3. Load train/test split files\n",
    "# ============================\n",
    "with open('/content/drive/MyDrive//train_val_list.txt') as f:\n",
    "    train_files = set(f.read().splitlines())\n",
    "with open('/content/drive/MyDrive/test_list.txt') as f:\n",
    "    test_files = set(f.read().splitlines())\n",
    "\n",
    "df[\"split\"] = df[\"Image Index\"].apply(\n",
    "    lambda x: \"train\" if x in train_files else (\"test\" if x in test_files else \"none\")\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 4. Clean Missing Images\n",
    "# ============================\n",
    "# Update the image directory path to the correct location in Google Drive\n",
    "IMG_DIR = '/content/drive/MyDrive/images' # Assuming the images are in a folder named 'images' within your Project/X_ray folder\n",
    "\n",
    "df = df[df[\"Image Index\"].apply(lambda x: os.path.exists(os.path.join(IMG_DIR, x)))]\n",
    "print(\"After removing missing images:\", len(df))\n",
    "\n",
    "# ============================\n",
    "# 5. Encode Labels\n",
    "# ============================\n",
    "df[\"Finding Labels\"] = df[\"Finding Labels\"].str.split(\"|\")\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df[\"Finding Labels\"])\n",
    "print(\"Classes:\", mlb.classes_)\n",
    "\n",
    "# ============================\n",
    "# 6. Dataset Class\n",
    "# ============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class CXRDataset(Dataset):\n",
    "    def __init__(self, df, labels, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row[\"Image Index\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx]).float()\n",
    "        return image, label\n",
    "\n",
    "train_df = df[df[\"split\"]==\"train\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"]==\"test\"].reset_index(drop=True)\n",
    "\n",
    "train_dataset = CXRDataset(train_df, y[df[\"split\"]==\"train\"], IMG_DIR, transform)\n",
    "test_dataset  = CXRDataset(test_df, y[df[\"split\"]==\"test\"], IMG_DIR, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Test samples:\", len(test_dataset))\n",
    "\n",
    "# ============================\n",
    "# 7. Define Model (DenseNet121)\n",
    "# ============================\n",
    "num_classes = len(mlb.classes_)\n",
    "\n",
    "model = models.densenet121(weights=\"IMAGENET1K_V1\")\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.classifier.in_features, num_classes),\n",
    "    nn.Sigmoid()   # multi-label\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 8. Train Loop\n",
    "# ============================\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ============================\n",
    "# 9. Evaluation\n",
    "# ============================\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        y_true.append(labels.cpu())\n",
    "        y_pred.append(outputs.cpu())\n",
    "\n",
    "y_true = torch.cat(y_true).numpy()\n",
    "y_pred = torch.cat(y_pred).numpy()\n",
    "\n",
    "print(\"Mean ROC AUC:\", roc_auc_score(y_true, y_pred, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (rdkit-env)",
   "language": "python",
   "name": "rdkit-env"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
